<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-logo">
                <img src="images/cikm_logo.jpg" alt="CIKM 2025" class="cikm-logo">
            </div>
            <ul class="nav-menu">
                <li><a href="#overview">Overview</a></li>
                <li><a href="#outline">Outline</a></li>
                <li><a href="#presenters">Presenters</a></li>
            </ul>
            <div class="nav-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-container">
            <div class="hero-content">
                <h1 class="hero-title">Generative Models for Synthetic Data</h1>
                <p class="hero-subtitle">CIKM 2025 Tutorial – Transforming Data Mining in the GenAI Era</p>
                <div class="hero-stats">
                    <div class="stat"><i class="fas fa-clock"></i><span>3 Hours</span><small>Half-day Session</small></div>
                    <div class="stat"><i class="fas fa-users"></i><span>Interactive</span><small>Hands-on Practice</small></div>
                    <div class="stat"><i class="fas fa-graduation-cap"></i><span>Expert-led</span><small>Cutting-Edge Insights</small></div>
                </div>
                <div class="hero-buttons">
                    <a href="#outline" class="btn btn-primary">View Tutorial Outline</a>
                    <a href="#presenters" class="btn btn-secondary">Meet the Presenters</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Overview Section -->
    <section id="overview" class="section">
        <div class="container">
            <div class="section-header"><h2>Overview</h2></div>
            <div class="overview-text">
                <p>Generative models—Large Language Models (LLMs), Diffusion Models, and Generative Adversarial Networks (GANs)—have revolutionized synthetic-data creation, offering scalable solutions to data scarcity, privacy, and annotation challenges in data mining.</p>
                <p>This tutorial surveys foundations and state-of-the-art advances in synthetic-data generation, details practical frameworks, and reviews evaluation strategies and real-world applications. Attendees will gain actionable insights into leveraging synthetic data for research and industrial pipelines.</p>
                <p>Targeted at researchers and practitioners in data mining, machine learning, NLP, vision, and multimodal analytics, the session equips participants to harness synthetic data effectively while understanding its opportunities and challenges.</p>
            </div>
        </div>
    </section>

    <!-- Tutorial Outline Section -->
    <section id="outline" class="section bg-light">
        <div class="container">
            <div class="section-header">
                <h2>Tutorial Outline</h2>
                <p>Eight modules spanning foundations, practice, and future directions</p>
            </div>

            <div class="timeline">
                <!-- 1 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-play"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">15 minutes</div>
                        <h3>Introduction &amp; Background</h3>
                        <p>Defining synthetic data and motivating factors: data scarcity, privacy, annotation cost, low-resource settings.</p>
                        <div class="timeline-tags"><span class="tag">Motivation</span><span class="tag">Foundations</span></div>
                    </div>
                </div>
                <!-- 2 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-microchip"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">30 minutes</div>
                        <h3>Core Generative Models</h3>
                        <p>Comparative deep-dive into GANs, Diffusion Models, and LLMs: architectures, strengths, and limitations.</p>
                        <div class="timeline-tags"><span class="tag">GANs</span><span class="tag">Diffusion</span><span class="tag">LLMs</span></div>
                    </div>
                </div>

                <!-- Break -->
                <div class="timeline-break"><i class="fas fa-coffee"></i><span>15-minute Break</span></div>

                <!-- 3 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-tools"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">20 minutes</div>
                        <h3>Synthetic Data in Practice</h3>
                        <p>Hands-on tour of frameworks such as MagPie, DataGen, DyVal (text) and TaskMeAnything, AutoBench-V (multimodal).</p>
                        <div class="timeline-tags"><span class="tag">Frameworks</span><span class="tag">Demo</span></div>
                    </div>
                </div>
                <!-- 4 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-chart-bar"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">20 minutes</div>
                        <h3>Evaluation &amp; Benchmarking</h3>
                        <p>Fidelity, diversity, controllability, and downstream-utility metrics; open challenges in bias and generalization.</p>
                        <div class="timeline-tags"><span class="tag">Metrics</span><span class="tag">Benchmarks</span></div>
                    </div>
                </div>
                <!-- 5 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-database"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">30 minutes</div>
                        <h3>Applications in Data Mining</h3>
                        <p>Use cases across text, tabular, graph, sequential, and multimodal data; boosting model robustness and privacy.</p>
                        <div class="timeline-tags"><span class="tag">Text</span><span class="tag">Tabular</span><span class="tag">Graph</span></div>
                    </div>
                </div>
                <!-- 6 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-globe"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">15 minutes</div>
                        <h3>Real-world Scenarios</h3>
                        <p>Case studies in healthcare, finance, and education demonstrating privacy-preserving synthetic data pipelines.</p>
                        <div class="timeline-tags"><span class="tag">Healthcare</span><span class="tag">Finance</span><span class="tag">Education</span></div>
                    </div>
                </div>
                <!-- 7 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-laptop-code"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">20 minutes</div>
                        <h3>Hands-on Practice</h3>
                        <p>Live demo notebook—generating synthetic text, tabular, graph, sequential, and visual data.</p>
                        <div class="timeline-tags"><span class="tag">Notebook</span><span class="tag">Demo</span></div>
                    </div>
                </div>
                <!-- 8 -->
                <div class="timeline-item">
                    <div class="timeline-marker"><i class="fas fa-comments"></i></div>
                    <div class="timeline-content">
                        <div class="timeline-time">15 minutes</div>
                        <h3>Challenges &amp; Future Directions</h3>
                        <p>Model-collapse risks, integrating traditional augmentation with GenAI, and open research questions (Q&amp;A).</p>
                        <div class="timeline-tags"><span class="tag">Discussion</span><span class="tag">Future</span></div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Presenters Section -->
    <section id="presenters" class="section">
        <div class="container">
            <div class="section-header"><h2>Presenters</h2></div>

            <div class="presenters-row">
                <!-- Dawei Li -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/daweili.png" alt="Dawei Li"></div>
                    <div class="presenter-info">
                        <h4>Dawei Li</h4>
                        <p class="presenter-title">Ph.D. Student – Arizona State University</p>
                        <div class="presenter-bio"><p>Dawei Li is a Ph.D. student in Computer Science at Arizona State University. Previously, He obtained his bachelor’s degree in Computer Science from Beijing Language and Cultural University and master’s degree in Data Science from the University of California, San Diego. His research focuses on techniques and risks from AI oversight. Dawei have published papers and served as reviewers in top NLP and Data Mining venues including ACL, EMNLP, NAACL, TKDD, PAKDD and SIGKDD Exploration.</p></div>
                    </div>
                </div>
                <!-- Yue Huang -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/yuehuang.jpeg" alt="Yue Huang"></div>
                    <div class="presenter-info">
                        <h4>Yue Huang</h4>
                        <p class="presenter-title">Ph.D. Student – University of Notre Dame</p>
                        <div class="presenter-bio"><p>Yue Huang is a Ph.D. student in Computer Science and Engineering at the University of Notre Dame. He earned his B.S.\ in Computer Science from Sichuan University. His research investigates the trustworthiness and social responsibility of foundation models. Yue has published extensively at premier venues including NeurIPS, ICLR, ICML, ACL, EMNLP, NAACL, CVPR, and IJCAI. His work has been highlighted by the U.S.\ Department of Homeland Security and recognized with the Microsoft Accelerating Foundation Models Research Award and the KAUST AI Rising Star Award (2025). </p></div>
                    </div>
                </div>
                <!-- Ming Li -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/mingli.png" alt="Ming Li"></div>
                    <div class="presenter-info">
                        <h4>Ming Li</h4>
                        <p class="presenter-title">Ph.D. Student – University of Maryland</p>
                        <div class="presenter-bio"><p>Ming Li is a Ph.D. student in Computer Science at the University of Maryland. Previously, He obtained his bachelor’s degree in Computer Science from Xi'an Jiaotong University and his master’s degree in Computer Science from Texas A\&M University. His research focuses on post-training for foundation models and responsible and self-evolving AI. Ming has published papers and served as a reviewer in top NLP and Machine Learning venues, including ACL, EMNLP, ICLR, NAACL, and etc.</p></div>
                    </div>
                </div>
                <!-- Tianyi Zhou -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/tianyizhou.png" alt="Tianyi Zhou"></div>
                    <div class="presenter-info">
                        <h4>Tianyi Zhou</h4>
                        <p class="presenter-title">Assistant Professor – University of Maryland</p>
                        <div class="presenter-bio"><p>Tianyi Zhou is a tenure-track assistant professor of Computer Science at the University of Maryland, College Park (UMD). He received his Ph.D. from the University of Washington and worked as a research scientist at Google before joining UMD. His research interests are machine learning, natural language processing, and multi-modal generative AI. His team has published >130 papers in ML (NeurIPS, ICML, ICLR), NLP (ACL, EMNLP, NAACL), CV (CVPR, ICCV, ECCV), and journals such as IEEE TPAMI/TIP/TNNLS/TKDE, with >10000 citations. He is the recipient of the best student paper of ICDM 2013. He has been serving as an area chair of ICLR, NeurIPS, ACL, EMNLP, SIGKDD, AAAI, IJCAI, WACV, etc.</p></div>
                    </div>
                </div>
                <!-- Xiangliang Zhang -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/xiangliangzhang.png" alt="Xiangliang Zhang"></div>
                    <div class="presenter-info">
                        <h4>Xiangliang Zhang</h4>
                        <p class="presenter-title">Leonard C. Bettex Collegiate Professor – University of Notre Dame</p>
                        <div class="presenter-bio"><p>Xiangliang Zhang is a Leonard C. Bettex Collegiate Professor in the Department of Computer Science and Engineering, University of Notre Dame. She was an Associate Professor in Computer Science at the King Abdullah University of Science and Technology (KAUST), Saudi Arabia. She received her Ph.D. degree in computer science from INRIA-Universite Paris Sud, France, in 2010. Her main research interests and experiences are in machine learning and data mining. She has published more than 270 refereed papers in leading international conferences and journals. She serves as associate editor of IEEE Transactions on Dependable and Secure Computing, Information Sciences, and International Journal of Intelligent Systems, and regularly serves as area chair or on the (senior) program committee of IJCAI, SIGKDD, NeurIPS, AAAI, ICML, and WSDM.</p></div>
                    </div>
                </div>
                <!-- Huan Liu -->
                <div class="presenter-item">
                    <div class="presenter-photo"><img src="images/huanliu.png" alt="Huan Liu"></div>
                    <div class="presenter-info">
                        <h4>Huan Liu</h4>
                        <p class="presenter-title">Regents Professor – Arizona State University</p>
                        <div class="presenter-bio"><p>Huan Liu is a Regent Professor in the School of Computing, and Augmented Intelligence, Arizona State University. He received his Ph.D. degree in Computer Science from the University of Southern California, in 1989. His research focuses on developing computational methods for data mining, machine learning, and social computing. Dr. Liu has been honored with numerous prestigious awards: ACM SIGKDD Innovation Award (2022) for his pioneering work in feature selection and social media mining, Fellow of ACM (2018), AAAI (2019), AAAS (2018), and IEEE (2012). He is Chief Editor of ACM TIST, Frontiers in Big Data and DMM, and has been actively involved on editorial boards and program committees for major conferences such as KDD, ICML, NeurIPS, AAAI, and IJCAI.</p></div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <script src="script.js"></script>
</body>
</html>
